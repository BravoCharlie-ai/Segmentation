{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import cv2, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aakashjuseja/anaconda3/envs/first-project/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=256\n",
    "classes=5\n",
    "image_dir='train_images'\n",
    "mask_dir='train_masks'\n",
    "data_shape = size*size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "import random\n",
    "percent=0.80\n",
    "val_image_dir='val_images'\n",
    "val_mask_dir='val_masks'\n",
    "data_shape=size*size\n",
    "import os\n",
    "\n",
    "def generate_paths(image_dir,mask_dir):\n",
    "    image_path = [os.path.join(image_dir, x) for x in sorted(os.listdir(image_dir)) if x.endswith('.png')]\n",
    "    mask_path = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir)) if x.endswith('.png')]\n",
    "    image_path = np.array(image_path)\n",
    "    mask_path = np.array(mask_path)\n",
    "    # Break data into testing and validation\n",
    "    data_size = image_path.shape[0]\n",
    "    random_index = np.random.permutation(data_size)\n",
    "    image_path = image_path[random_index]\n",
    "    mask_path = mask_path[random_index]\n",
    "    \n",
    "    # first 80 percent of dataset are for training\n",
    "    X_tr = image_path[:int(data_size * percent)]\n",
    "    Y_tr = mask_path[:int(data_size * percent)]\n",
    "    # remaining subset is for validation\n",
    "    X_val = image_path[int(data_size * percent):]\n",
    "    Y_val = mask_path[int(data_size * percent):]\n",
    "    return X_tr,Y_tr,X_val,Y_val\n",
    "\n",
    "def onehot_label(label):\n",
    "    \"\"\"\n",
    "    Converts labels to onehot array.\n",
    "    Returns: (h, w, classes)\n",
    "    \"\"\"\n",
    "    classes = classes\n",
    "    mask = np.eye(classes)[label]\n",
    "    return mask\n",
    "def hot_encoder(label):\n",
    "    mask = np.zeros((size, size, classes))\n",
    "    for c in range(classes):\n",
    "        mask[:,:,c] = (label==c).astype(int)\n",
    "        \n",
    "    return mask\n",
    "    \n",
    "def preprocess_inputs(self, X):\n",
    "    return imagenet_utils.preprocess_input(X)\n",
    "\n",
    "def reshape_labels(y):\n",
    "    return np.reshape(y, (data_shape, classes))\n",
    "    \n",
    "\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "  c = 0\n",
    "  n = os.listdir(img_folder) #List of training images\n",
    "  random.shuffle(n)\n",
    "  \n",
    "  while (True):\n",
    "    img = np.zeros((batch_size,size , size, 3)).astype('float')\n",
    "    mask = np.zeros((batch_size, size, size, 5)).astype('float')\n",
    "\n",
    "    for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n",
    "\n",
    "      train_img = cv2.imread(img_folder+'/'+n[i])/255.0\n",
    "      #train_img =  cv2.resize(train_img, (size, size))# Read an image from folder and resize\n",
    "\n",
    "      img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "    \n",
    "      #train_mask = cv2.imread(mask_folder+'/'+n[i], 0)\n",
    "\n",
    "      train_mask = hot_encoder(cv2.resize(cv2.imread(mask_folder+'/'+n[i], 0),(size,size)))\n",
    "      #train_mask = train_mask.reshape(512, 512, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "      mask[i-c] = train_mask\n",
    "\n",
    "    c+=batch_size\n",
    "    if(c+batch_size>=len(os.listdir(img_folder))):\n",
    "      c=0\n",
    "      random.shuffle(n)\n",
    "                  # print \"randomizing again\"\n",
    "    yield img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation, Reshape, Permute\n",
    "from keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Conv2DTranspose,concatenate,Dropout\n",
    "from keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n",
    "    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Unet(img_height, img_width, nclasses=5, filters=64):\n",
    "# down\n",
    "    input_layer = Input(shape=(img_height, img_width, 3), name='image_input')\n",
    "    conv1 = conv_block(input_layer, nfilters=filters)\n",
    "    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_block(conv1_out, nfilters=filters*2)\n",
    "    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv_block(conv2_out, nfilters=filters*4)\n",
    "    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv_block(conv3_out, nfilters=filters*8)\n",
    "    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4_out = Dropout(0.5)(conv4_out)\n",
    "    conv5 = conv_block(conv4_out, nfilters=filters*16)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "# up\n",
    "    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n",
    "    deconv6 = Dropout(0.5)(deconv6)\n",
    "    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n",
    "    deconv7 = Dropout(0.5)(deconv7) \n",
    "    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n",
    "    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n",
    "# output\n",
    "    output_layer = Conv2D(filters=nclasses, kernel_size=(1, 1))(deconv9)\n",
    "    output_layer = BatchNormalization()(output_layer)\n",
    "    output_layer = Activation('softmax')(output_layer)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel =3\n",
    "input_shape= (size, size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Unet(size,size, nclasses=classes,filters=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model=load_model('unet_002.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_gen = data_gen(image_dir,mask_dir, batch_size = batch_size)\n",
    "val_gen = data_gen(val_image_dir,val_mask_dir, batch_size =batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[]\n",
    "from keras.models import load_model\n",
    "model=load_model('unet_001-35-0.59.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opt=optimizers.Adam(lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "734/734 [==============================] - 703s 957ms/step - loss: 0.2514 - acc: 0.9125 - val_loss: 0.5783 - val_acc: 0.7945\n",
      "Epoch 38/500\n",
      "734/734 [==============================] - 684s 932ms/step - loss: 0.2423 - acc: 0.9164 - val_loss: 0.5664 - val_acc: 0.7990\n",
      "Epoch 39/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.2359 - acc: 0.9183 - val_loss: 0.5885 - val_acc: 0.7959\n",
      "Epoch 40/500\n",
      "734/734 [==============================] - 696s 948ms/step - loss: 0.2327 - acc: 0.9196 - val_loss: 0.5809 - val_acc: 0.7976\n",
      "Epoch 41/500\n",
      "734/734 [==============================] - 698s 951ms/step - loss: 0.2269 - acc: 0.9212 - val_loss: 0.5755 - val_acc: 0.8015\n",
      "Epoch 42/500\n",
      "734/734 [==============================] - 701s 955ms/step - loss: 0.2251 - acc: 0.9217 - val_loss: 0.5648 - val_acc: 0.8034\n",
      "Epoch 43/500\n",
      "734/734 [==============================] - 703s 957ms/step - loss: 0.2228 - acc: 0.9225 - val_loss: 0.5820 - val_acc: 0.8002\n",
      "Epoch 44/500\n",
      "734/734 [==============================] - 701s 956ms/step - loss: 0.2196 - acc: 0.9235 - val_loss: 0.5818 - val_acc: 0.8013\n",
      "Epoch 45/500\n",
      "734/734 [==============================] - 702s 957ms/step - loss: 0.2192 - acc: 0.9240 - val_loss: 0.5778 - val_acc: 0.8013\n",
      "Epoch 46/500\n",
      "734/734 [==============================] - 709s 966ms/step - loss: 0.2157 - acc: 0.9251 - val_loss: 0.5763 - val_acc: 0.8023\n",
      "Epoch 47/500\n",
      "734/734 [==============================] - 702s 957ms/step - loss: 0.2141 - acc: 0.9256 - val_loss: 0.5879 - val_acc: 0.8015\n",
      "Epoch 48/500\n",
      "734/734 [==============================] - 693s 944ms/step - loss: 0.2119 - acc: 0.9258 - val_loss: 0.5915 - val_acc: 0.7989\n",
      "Epoch 49/500\n",
      "734/734 [==============================] - 696s 948ms/step - loss: 0.2094 - acc: 0.9269 - val_loss: 0.5994 - val_acc: 0.7987\n",
      "Epoch 50/500\n",
      "734/734 [==============================] - 694s 945ms/step - loss: 0.2097 - acc: 0.9272 - val_loss: 0.5859 - val_acc: 0.8010\n",
      "Epoch 51/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.2061 - acc: 0.9280 - val_loss: 0.5922 - val_acc: 0.7995\n",
      "Epoch 52/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.2025 - acc: 0.9289 - val_loss: 0.6038 - val_acc: 0.7992\n",
      "Epoch 53/500\n",
      "734/734 [==============================] - 695s 946ms/step - loss: 0.2057 - acc: 0.9284 - val_loss: 0.5791 - val_acc: 0.8060\n",
      "Epoch 54/500\n",
      "734/734 [==============================] - 691s 942ms/step - loss: 0.2010 - acc: 0.9296 - val_loss: 0.5867 - val_acc: 0.8026\n",
      "Epoch 55/500\n",
      "734/734 [==============================] - 693s 945ms/step - loss: 0.1986 - acc: 0.9303 - val_loss: 0.5898 - val_acc: 0.8036\n",
      "Epoch 56/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1977 - acc: 0.9308 - val_loss: 0.5896 - val_acc: 0.8031\n",
      "Epoch 57/500\n",
      "734/734 [==============================] - 695s 947ms/step - loss: 0.1964 - acc: 0.9312 - val_loss: 0.5952 - val_acc: 0.8018\n",
      "Epoch 58/500\n",
      "734/734 [==============================] - 696s 948ms/step - loss: 0.1957 - acc: 0.9312 - val_loss: 0.6015 - val_acc: 0.8010\n",
      "Epoch 59/500\n",
      "734/734 [==============================] - 694s 945ms/step - loss: 0.1943 - acc: 0.9320 - val_loss: 0.5942 - val_acc: 0.8016\n",
      "Epoch 60/500\n",
      "734/734 [==============================] - 689s 939ms/step - loss: 0.1936 - acc: 0.9322 - val_loss: 0.6342 - val_acc: 0.7949\n",
      "Epoch 61/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1904 - acc: 0.9331 - val_loss: 0.6125 - val_acc: 0.8004\n",
      "Epoch 62/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1898 - acc: 0.9333 - val_loss: 0.6140 - val_acc: 0.8009\n",
      "Epoch 63/500\n",
      "734/734 [==============================] - 690s 941ms/step - loss: 0.1893 - acc: 0.9335 - val_loss: 0.6188 - val_acc: 0.7947\n",
      "Epoch 64/500\n",
      "734/734 [==============================] - 691s 942ms/step - loss: 0.1876 - acc: 0.9341 - val_loss: 0.6053 - val_acc: 0.8029\n",
      "Epoch 65/500\n",
      "734/734 [==============================] - 693s 945ms/step - loss: 0.1847 - acc: 0.9348 - val_loss: 0.6268 - val_acc: 0.7974\n",
      "Epoch 66/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1854 - acc: 0.9348 - val_loss: 0.6021 - val_acc: 0.8035\n",
      "Epoch 67/500\n",
      "734/734 [==============================] - 689s 938ms/step - loss: 0.1853 - acc: 0.9347 - val_loss: 0.6007 - val_acc: 0.8033\n",
      "Epoch 68/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1810 - acc: 0.9361 - val_loss: 0.6097 - val_acc: 0.8013\n",
      "Epoch 69/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1802 - acc: 0.9363 - val_loss: 0.6034 - val_acc: 0.8030\n",
      "Epoch 70/500\n",
      "734/734 [==============================] - 688s 938ms/step - loss: 0.1782 - acc: 0.9369 - val_loss: 0.6159 - val_acc: 0.8007\n",
      "Epoch 71/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1791 - acc: 0.9368 - val_loss: 0.6336 - val_acc: 0.7971\n",
      "Epoch 72/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1769 - acc: 0.9373 - val_loss: 0.6180 - val_acc: 0.8026\n",
      "Epoch 73/500\n",
      "734/734 [==============================] - 682s 930ms/step - loss: 0.1768 - acc: 0.9372 - val_loss: 0.6280 - val_acc: 0.8010\n",
      "Epoch 74/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1756 - acc: 0.9378 - val_loss: 0.6257 - val_acc: 0.8014\n",
      "Epoch 75/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1744 - acc: 0.9381 - val_loss: 0.6322 - val_acc: 0.7991\n",
      "Epoch 76/500\n",
      "734/734 [==============================] - 682s 930ms/step - loss: 0.1722 - acc: 0.9387 - val_loss: 0.6124 - val_acc: 0.8039\n",
      "Epoch 77/500\n",
      "734/734 [==============================] - 715s 975ms/step - loss: 0.1724 - acc: 0.9388 - val_loss: 0.6257 - val_acc: 0.8006\n",
      "Epoch 78/500\n",
      "734/734 [==============================] - 683s 930ms/step - loss: 0.1623 - acc: 0.9418 - val_loss: 0.6369 - val_acc: 0.8028\n",
      "Epoch 87/500\n",
      "734/734 [==============================] - 680s 927ms/step - loss: 0.1608 - acc: 0.9424 - val_loss: 0.6320 - val_acc: 0.8011\n",
      "Epoch 88/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1604 - acc: 0.9426 - val_loss: 0.6381 - val_acc: 0.8012\n",
      "Epoch 89/500\n",
      "734/734 [==============================] - 685s 933ms/step - loss: 0.1586 - acc: 0.9430 - val_loss: 0.6421 - val_acc: 0.7998\n",
      "Epoch 90/500\n",
      "734/734 [==============================] - 682s 929ms/step - loss: 0.1592 - acc: 0.9428 - val_loss: 0.6313 - val_acc: 0.8030\n",
      "Epoch 91/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1552 - acc: 0.9441 - val_loss: 0.6382 - val_acc: 0.8030\n",
      "Epoch 92/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1575 - acc: 0.9433 - val_loss: 0.6665 - val_acc: 0.7985\n",
      "Epoch 93/500\n",
      "734/734 [==============================] - 685s 934ms/step - loss: 0.1571 - acc: 0.9434 - val_loss: 0.6550 - val_acc: 0.7997\n",
      "Epoch 94/500\n",
      "734/734 [==============================] - 684s 932ms/step - loss: 0.1535 - acc: 0.9446 - val_loss: 0.6444 - val_acc: 0.8027\n",
      "Epoch 95/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1551 - acc: 0.9444 - val_loss: 0.6315 - val_acc: 0.8037\n",
      "Epoch 96/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1511 - acc: 0.9451 - val_loss: 0.6437 - val_acc: 0.8025\n",
      "Epoch 97/500\n",
      "734/734 [==============================] - 681s 927ms/step - loss: 0.1518 - acc: 0.9452 - val_loss: 0.6559 - val_acc: 0.8012\n",
      "Epoch 98/500\n",
      "734/734 [==============================] - 678s 924ms/step - loss: 0.1517 - acc: 0.9453 - val_loss: 0.6625 - val_acc: 0.7997\n",
      "Epoch 99/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1500 - acc: 0.9456 - val_loss: 0.6766 - val_acc: 0.7967\n",
      "Epoch 100/500\n",
      "734/734 [==============================] - 680s 927ms/step - loss: 0.1498 - acc: 0.9459 - val_loss: 0.6617 - val_acc: 0.7986\n",
      "Epoch 101/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1480 - acc: 0.9463 - val_loss: 0.6530 - val_acc: 0.8033\n",
      "Epoch 102/500\n",
      "734/734 [==============================] - 683s 930ms/step - loss: 0.1475 - acc: 0.9463 - val_loss: 0.6773 - val_acc: 0.7984\n",
      "Epoch 103/500\n",
      "734/734 [==============================] - 680s 927ms/step - loss: 0.1445 - acc: 0.9473 - val_loss: 0.6694 - val_acc: 0.7997\n",
      "Epoch 104/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1451 - acc: 0.9470 - val_loss: 0.6614 - val_acc: 0.7989\n",
      "Epoch 105/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1469 - acc: 0.9464 - val_loss: 0.6584 - val_acc: 0.8011\n",
      "Epoch 106/500\n",
      "734/734 [==============================] - 687s 936ms/step - loss: 0.1459 - acc: 0.9469 - val_loss: 0.6522 - val_acc: 0.8026\n",
      "Epoch 107/500\n",
      "734/734 [==============================] - 684s 931ms/step - loss: 0.1436 - acc: 0.9477 - val_loss: 0.6883 - val_acc: 0.7958\n",
      "Epoch 108/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1422 - acc: 0.9481 - val_loss: 0.6507 - val_acc: 0.8026\n",
      "Epoch 109/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1417 - acc: 0.9481 - val_loss: 0.6689 - val_acc: 0.8017\n",
      "Epoch 110/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1424 - acc: 0.9481 - val_loss: 0.6577 - val_acc: 0.8043\n",
      "Epoch 111/500\n",
      "734/734 [==============================] - 688s 937ms/step - loss: 0.1413 - acc: 0.9484 - val_loss: 0.6572 - val_acc: 0.8024\n",
      "Epoch 112/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1396 - acc: 0.9488 - val_loss: 0.7101 - val_acc: 0.7946\n",
      "Epoch 113/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1396 - acc: 0.9488 - val_loss: 0.6620 - val_acc: 0.8029\n",
      "Epoch 114/500\n",
      "734/734 [==============================] - 683s 930ms/step - loss: 0.1379 - acc: 0.9493 - val_loss: 0.6655 - val_acc: 0.8024\n",
      "Epoch 115/500\n",
      "734/734 [==============================] - 678s 924ms/step - loss: 0.1378 - acc: 0.9494 - val_loss: 0.7066 - val_acc: 0.7961\n",
      "Epoch 116/500\n",
      "734/734 [==============================] - 679s 926ms/step - loss: 0.1365 - acc: 0.9500 - val_loss: 0.6595 - val_acc: 0.8053\n",
      "Epoch 117/500\n",
      "734/734 [==============================] - 678s 924ms/step - loss: 0.1390 - acc: 0.9490 - val_loss: 0.6821 - val_acc: 0.8012\n",
      "Epoch 118/500\n",
      "734/734 [==============================] - 680s 927ms/step - loss: 0.1362 - acc: 0.9500 - val_loss: 0.6568 - val_acc: 0.8047\n",
      "Epoch 119/500\n",
      "734/734 [==============================] - 683s 930ms/step - loss: 0.1343 - acc: 0.9505 - val_loss: 0.6700 - val_acc: 0.8050\n",
      "Epoch 120/500\n",
      "734/734 [==============================] - 678s 923ms/step - loss: 0.1337 - acc: 0.9507 - val_loss: 0.6734 - val_acc: 0.8035\n",
      "Epoch 121/500\n",
      "734/734 [==============================] - 680s 926ms/step - loss: 0.1330 - acc: 0.9509 - val_loss: 0.6726 - val_acc: 0.8042\n",
      "Epoch 122/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1336 - acc: 0.9506 - val_loss: 0.6779 - val_acc: 0.8032\n",
      "Epoch 123/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1319 - acc: 0.9512 - val_loss: 0.6779 - val_acc: 0.8031\n",
      "Epoch 124/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1308 - acc: 0.9517 - val_loss: 0.6804 - val_acc: 0.8016\n",
      "Epoch 125/500\n",
      "734/734 [==============================] - 681s 927ms/step - loss: 0.1295 - acc: 0.9519 - val_loss: 0.6886 - val_acc: 0.8002\n",
      "Epoch 126/500\n",
      "734/734 [==============================] - 681s 928ms/step - loss: 0.1304 - acc: 0.9518 - val_loss: 0.6755 - val_acc: 0.8012\n",
      "Epoch 127/500\n",
      "734/734 [==============================] - 681s 927ms/step - loss: 0.1319 - acc: 0.9513 - val_loss: 0.6782 - val_acc: 0.8030\n",
      "Epoch 128/500\n",
      "734/734 [==============================] - 679s 925ms/step - loss: 0.1277 - acc: 0.9525 - val_loss: 0.6926 - val_acc: 0.8012\n",
      "Epoch 129/500\n",
      "734/734 [==============================] - 680s 927ms/step - loss: 0.1277 - acc: 0.9526 - val_loss: 0.6846 - val_acc: 0.8018\n",
      "Epoch 130/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1269 - acc: 0.9527 - val_loss: 0.6887 - val_acc: 0.8017\n",
      "Epoch 131/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.1271 - acc: 0.9528 - val_loss: 0.6829 - val_acc: 0.8043\n",
      "Epoch 132/500\n",
      "734/734 [==============================] - 691s 942ms/step - loss: 0.1265 - acc: 0.9530 - val_loss: 0.6977 - val_acc: 0.8003\n",
      "Epoch 133/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1252 - acc: 0.9533 - val_loss: 0.6952 - val_acc: 0.7989\n",
      "Epoch 134/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1259 - acc: 0.9532 - val_loss: 0.6870 - val_acc: 0.8027\n",
      "Epoch 135/500\n",
      "734/734 [==============================] - 693s 944ms/step - loss: 0.1261 - acc: 0.9532 - val_loss: 0.6852 - val_acc: 0.8020\n",
      "Epoch 136/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1241 - acc: 0.9537 - val_loss: 0.7005 - val_acc: 0.8014\n",
      "Epoch 137/500\n",
      "734/734 [==============================] - 693s 945ms/step - loss: 0.1234 - acc: 0.9540 - val_loss: 0.7053 - val_acc: 0.8015\n",
      "Epoch 138/500\n",
      "734/734 [==============================] - 694s 945ms/step - loss: 0.1220 - acc: 0.9542 - val_loss: 0.7090 - val_acc: 0.8013\n",
      "Epoch 139/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1224 - acc: 0.9542 - val_loss: 0.7007 - val_acc: 0.8020\n",
      "Epoch 140/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1212 - acc: 0.9545 - val_loss: 0.7156 - val_acc: 0.8025\n",
      "Epoch 141/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.1221 - acc: 0.9545 - val_loss: 0.6959 - val_acc: 0.8026\n",
      "Epoch 142/500\n",
      "734/734 [==============================] - 690s 940ms/step - loss: 0.1207 - acc: 0.9546 - val_loss: 0.7043 - val_acc: 0.8015\n",
      "Epoch 143/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1198 - acc: 0.9552 - val_loss: 0.6939 - val_acc: 0.8032\n",
      "Epoch 144/500\n",
      "734/734 [==============================] - 697s 949ms/step - loss: 0.1189 - acc: 0.9552 - val_loss: 0.6953 - val_acc: 0.8030\n",
      "Epoch 145/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1193 - acc: 0.9552 - val_loss: 0.7065 - val_acc: 0.8005\n",
      "Epoch 146/500\n",
      "734/734 [==============================] - 695s 947ms/step - loss: 0.1176 - acc: 0.9557 - val_loss: 0.7011 - val_acc: 0.8023\n",
      "Epoch 147/500\n",
      "734/734 [==============================] - 689s 939ms/step - loss: 0.1180 - acc: 0.9555 - val_loss: 0.7169 - val_acc: 0.8021\n",
      "Epoch 148/500\n",
      "734/734 [==============================] - 690s 940ms/step - loss: 0.1179 - acc: 0.9556 - val_loss: 0.7153 - val_acc: 0.8023\n",
      "Epoch 149/500\n",
      "734/734 [==============================] - 692s 943ms/step - loss: 0.1170 - acc: 0.9560 - val_loss: 0.7118 - val_acc: 0.8009\n",
      "Epoch 150/500\n",
      "734/734 [==============================] - 693s 945ms/step - loss: 0.1157 - acc: 0.9563 - val_loss: 0.7021 - val_acc: 0.8035\n",
      "Epoch 151/500\n",
      "734/734 [==============================] - 691s 942ms/step - loss: 0.1167 - acc: 0.9562 - val_loss: 0.7123 - val_acc: 0.8031\n",
      "Epoch 152/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.1153 - acc: 0.9564 - val_loss: 0.7070 - val_acc: 0.8011\n",
      "Epoch 153/500\n",
      "734/734 [==============================] - 694s 946ms/step - loss: 0.1148 - acc: 0.9567 - val_loss: 0.7097 - val_acc: 0.8034\n",
      "Epoch 154/500\n",
      "734/734 [==============================] - 688s 938ms/step - loss: 0.1137 - acc: 0.9570 - val_loss: 0.7061 - val_acc: 0.8027\n",
      "Epoch 155/500\n",
      "734/734 [==============================] - 687s 936ms/step - loss: 0.1137 - acc: 0.9569 - val_loss: 0.7174 - val_acc: 0.8019\n",
      "Epoch 156/500\n",
      "734/734 [==============================] - 688s 938ms/step - loss: 0.1135 - acc: 0.9571 - val_loss: 0.7459 - val_acc: 0.7947\n",
      "Epoch 157/500\n",
      "734/734 [==============================] - 689s 939ms/step - loss: 0.1129 - acc: 0.9572 - val_loss: 0.7342 - val_acc: 0.7995\n",
      "Epoch 158/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1123 - acc: 0.9576 - val_loss: 0.7210 - val_acc: 0.8028\n",
      "Epoch 159/500\n",
      "734/734 [==============================] - 688s 937ms/step - loss: 0.1122 - acc: 0.9576 - val_loss: 0.7202 - val_acc: 0.8019\n",
      "Epoch 160/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1123 - acc: 0.9575 - val_loss: 0.7419 - val_acc: 0.7992\n",
      "Epoch 161/500\n",
      "734/734 [==============================] - 687s 936ms/step - loss: 0.1125 - acc: 0.9574 - val_loss: 0.7177 - val_acc: 0.8029\n",
      "Epoch 162/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1106 - acc: 0.9581 - val_loss: 0.7471 - val_acc: 0.7955\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 688s 937ms/step - loss: 0.1104 - acc: 0.9581 - val_loss: 0.7288 - val_acc: 0.7994\n",
      "Epoch 164/500\n",
      "734/734 [==============================] - 690s 940ms/step - loss: 0.1104 - acc: 0.9580 - val_loss: 0.7242 - val_acc: 0.8009\n",
      "Epoch 165/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1086 - acc: 0.9587 - val_loss: 0.7413 - val_acc: 0.7990\n",
      "Epoch 166/500\n",
      "734/734 [==============================] - 691s 941ms/step - loss: 0.1082 - acc: 0.9587 - val_loss: 0.7328 - val_acc: 0.8004\n",
      "Epoch 167/500\n",
      "734/734 [==============================] - 692s 942ms/step - loss: 0.1087 - acc: 0.9585 - val_loss: 0.7365 - val_acc: 0.8015\n",
      "Epoch 168/500\n",
      "734/734 [==============================] - 690s 939ms/step - loss: 0.1078 - acc: 0.9591 - val_loss: 0.7493 - val_acc: 0.8009\n",
      "Epoch 169/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1068 - acc: 0.9591 - val_loss: 0.7292 - val_acc: 0.8023\n",
      "Epoch 170/500\n",
      "734/734 [==============================] - 688s 938ms/step - loss: 0.1099 - acc: 0.9582 - val_loss: 0.8116 - val_acc: 0.7844\n",
      "Epoch 171/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1069 - acc: 0.9593 - val_loss: 0.7290 - val_acc: 0.8021\n",
      "Epoch 172/500\n",
      "734/734 [==============================] - 692s 942ms/step - loss: 0.1066 - acc: 0.9592 - val_loss: 0.7711 - val_acc: 0.7955\n",
      "Epoch 173/500\n",
      "734/734 [==============================] - 686s 935ms/step - loss: 0.1051 - acc: 0.9597 - val_loss: 0.7442 - val_acc: 0.8008\n",
      "Epoch 174/500\n",
      "734/734 [==============================] - 686s 934ms/step - loss: 0.1066 - acc: 0.9595 - val_loss: 0.7279 - val_acc: 0.8010\n",
      "Epoch 175/500\n",
      "734/734 [==============================] - 685s 933ms/step - loss: 0.1067 - acc: 0.9593 - val_loss: 0.7392 - val_acc: 0.8017\n",
      "Epoch 176/500\n",
      "734/734 [==============================] - 688s 937ms/step - loss: 0.1037 - acc: 0.9602 - val_loss: 0.7390 - val_acc: 0.8022\n",
      "Epoch 177/500\n",
      "734/734 [==============================] - 684s 931ms/step - loss: 0.1043 - acc: 0.9601 - val_loss: 0.7416 - val_acc: 0.8029\n",
      "Epoch 178/500\n",
      "734/734 [==============================] - 687s 936ms/step - loss: 0.1033 - acc: 0.9603 - val_loss: 0.7359 - val_acc: 0.8050\n",
      "Epoch 179/500\n",
      "734/734 [==============================] - 685s 933ms/step - loss: 0.1035 - acc: 0.9603 - val_loss: 0.7415 - val_acc: 0.8025\n",
      "Epoch 180/500\n",
      "734/734 [==============================] - 685s 934ms/step - loss: 0.1039 - acc: 0.9601 - val_loss: 0.7301 - val_acc: 0.8044\n",
      "Epoch 181/500\n",
      "734/734 [==============================] - 685s 933ms/step - loss: 0.1025 - acc: 0.9606 - val_loss: 0.7450 - val_acc: 0.8020\n",
      "Epoch 182/500\n",
      "734/734 [==============================] - 682s 929ms/step - loss: 0.1046 - acc: 0.9601 - val_loss: 0.7493 - val_acc: 0.8014\n",
      "Epoch 183/500\n",
      "734/734 [==============================] - 683s 930ms/step - loss: 0.1024 - acc: 0.9607 - val_loss: 0.7393 - val_acc: 0.8023\n",
      "Epoch 184/500\n",
      "734/734 [==============================] - 683s 931ms/step - loss: 0.1015 - acc: 0.9610 - val_loss: 0.7646 - val_acc: 0.8014\n",
      "Epoch 185/500\n",
      "153/734 [=====>........................] - ETA: 8:43 - loss: 0.1006 - acc: 0.9613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c8a726e238b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                        \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                         initial_epoch=36)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/first-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "num_training_samples=np.array(os.listdir(image_dir)).shape[0]\n",
    "num_epochs=500\n",
    "num_validation_samples=np.array(os.listdir(val_image_dir)).shape[0]\n",
    "\n",
    "\n",
    "    # load data\n",
    "#(num_training_samples // batch_size)\n",
    "filepath = \"unet_001-{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "tb_cb = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "model.fit_generator(generator=train_gen,\n",
    "                                      steps_per_epoch=(num_training_samples // batch_size),\n",
    "                                      epochs=num_epochs,\n",
    "                                      verbose=1,\n",
    "                                        validation_data=val_gen,\n",
    "                                        validation_steps=(num_validation_samples // batch_size),\n",
    "                                      use_multiprocessing=True,\n",
    "                                      workers=1,\n",
    "                                      max_queue_size=1,\n",
    "                                       callbacks=[tb_cb],\n",
    "                                        initial_epoch=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
